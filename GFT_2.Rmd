---
title: "frontiersGap"
author: "Hadil"
date: "2024-03-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
settingAGQ=0
```

```{r}
library(readxl)
frontiersGap_final <- read_excel("frontiersGap_final.xlsx")
View(frontiersGap_final)
```

```{r}
library(readxl)

# Define the col_types vector for 37 columns
col_types <- c("text",    # First column: text
               "text",    # Second column: text
               rep("numeric", 5),  # Columns 3 to 7: numeric
               "text",    # Eighth column: text
               "numeric", # Ninth column: numeric
               "text",    # Tenth column: text
               rep("numeric", 9),  # Columns 11 to 19: numeric
               "text",    # Twentieth column: text
               rep("numeric", 21))  # Columns 21 to 41: numeric

# Read the Excel file with the specified column types
frontiersGap_final <- read_excel("~/Desktop/frontiersGAP/frontiersGap_final.xlsx", 
                             col_types = col_types, 
                             na = "Not Applicable")

# View the data
View(frontiersGap_final)
```
```{r}
# Convert it to an ordered factor if you want R to treat it as ordinal:
frontiersGap_final$ses <- factor(frontiersGap_final$ses, levels = c(1, 2, 3, 4,5,6,7,8,9,10), ordered = TRUE)
frontiersGap_final$edu <- factor(frontiersGap_final$edu, levels = c(1, 2, 3, 4,5,6,7), ordered = TRUE)

```
```{r}
str(frontiersGap_final)
```

```{r}
frontiersGap_final$ses <- as.ordered(frontiersGap_final$ses)
frontiersGap_final$edu <- as.ordered(frontiersGap_final$edu)
class(frontiersGap_final$edu)
str(frontiersGap_final)
unique(frontiersGap_final$aor)
frontiersGap_final$aor <- as.numeric(frontiersGap_final$aor)
```


```{r}
install.packages("optimx")
install.packages("lme4")
install.packages("Matrix")
install.packages("ggplot2")
install.packages("usethis")
install.packages("tidyverse")
install.packages("nlme")
install.packages("janitor")
install.packages("ggthemr")
devtools::install_github('cttobin/ggthemr')
devtools::install_github("hadley/devtools")
install.packages("lmerTest")
install.packages("devtools")
install.packages("emmeans")
install.packages("ggthemr")


```


```{r}
library(Matrix)
library(readxl)
library(usethis)
library(ggplot2)
library(lme4)
library(devtools)
library(optimx)
library(brms)
library(ggeffects)
library(dplyr)
library(tidyverse)
library(nlme)
library(lmerTest)
library(ggthemr)
library(DT)
library(ggdist)
```

```{r}
frontiersGap_final %>%
  group_by(group) %>%
  group_by(condition, group) %>%
  summarise(across(
    where(is.numeric),
    list(mean = ~mean(.x, na.rm = TRUE),
         count = ~sum(!is.na(.x)),
         sd = ~sd(.x, na.rm = TRUE),
         range = ~diff(range(.x, na.rm = TRUE)),
         min = ~min(.x, na.rm = TRUE),     # Add minimum calculation
         max = ~max(.x, na.rm = TRUE)      # Add maximum calculation
    ))) 
```


```{r}
library(dplyr)

frontiersGap_final %>%
  group_by(group, condition) %>%
  summarise(
    accuracy = mean(accuracy, na.rm = TRUE),
    count = sum(!is.na(accuracy))
  )
```
```{r}
library(dplyr)

frontiersGap_final %>%
  group_by(group) %>%
  summarise(
    accuracy_total = mean(accuracy, na.rm = TRUE),
    total_count = sum(!is.na(accuracy))
  )
```
```{r}
library(dplyr)

frontiersGap_final %>%
  group_by(condition, group) %>%
  summarise(
    accuracy_total = mean(accuracy, na.rm = TRUE),
    total_count = sum(!is.na(accuracy))
  )
```

```{r}
frontiersGap_final$Condition = ifelse(frontiersGap_final$condition == "CONG", -0.5, 0.5)
```

```{r}
library(dplyr)

frontiers_long %>%
  group_by(group, condition) %>%
  summarise(
    total_accuracy = sum(accuracy) / n()
  )
```
```{r}
library(dplyr)

frontiers_long %>%
  group_by(group, condition) %>%
  summarise(
    total_correct = sum(accuracy),
    total_incorrect = sum(23 - accuracy),
    total_attempts = n() * 23,  # Multiply by 23 to get the total possible attempts
    total_accuracy = total_correct / total_attempts
  )
```


```{r}
frontiersGap_final %>%
  group_by(group) %>%
  summarise(across(
    where(is.numeric),
    list(mean = ~mean(.x, na.rm = TRUE),
         count = ~sum(!is.na(.x)),
         sd = ~sd(.x, na.rm = TRUE),     # Add standard deviation calculation
         range = ~diff(range(.x, na.rm = TRUE)),   # Add range calculation
         min = ~min(.x, na.rm = TRUE),     # Add minimum calculation
         max = ~max(.x, na.rm = TRUE))     # Add maximum calculation
  ))
```
```{r}
frontiersGap_final %>%
  group_by(condition, group) %>%
  summarise(across(
    where(is.numeric),
    list(mean = ~mean(.x, na.rm = TRUE),
         count = ~sum(!is.na(.x)),
         sd = ~sd(.x, na.rm = TRUE),
         range = ~diff(range(.x, na.rm = TRUE)),
         min = ~min(.x, na.rm = TRUE),
         max = ~max(.x, na.rm = TRUE))
  ))
```
```{r}
frontiersGap_final %>%
  group_by(condition, group) %>%
  summarise(
    mean_rt = mean(rt, na.rm = TRUE),
    correct_count = sum(accuracy, na.rm = TRUE)
  )
```

```{r}
hist(frontiersGap_final$mean_rt_incong)
```

```{r}
frontiersGap_final$condition = ifelse(frontiersGap_final$condition == "CONG", -0.5, 0.5)
```


```{r}
hist(frontiersGap_final$RT)
log_rt_gapfrontiers <- log(frontiersGap_final$RT)
hist(log_rt_gapfrontiers)
```


# RT per condition


```{r}
frontiersGap_final |>
  ggplot(aes(x = group, y = log_rt_gapfrontiers, fill = condition)) +
  geom_boxplot()
```


```{r}
frontiersGap_final|>
  mutate(accuracy = as.numeric(as.character(accuracy))) %>%
  ggplot(aes(x = condition, y = accuracy, fill = group)) +
  geom_boxplot()
```


```{r}
frontiersGap_final$Dominance_score <- scale(frontiersGap_final$Dominance_score, center = TRUE, scale = TRUE)
frontiersGap_final$English_use <- scale(frontiersGap_final$English_use, center = TRUE, scale = TRUE)
frontiersGap_final$Arabic_use <- scale(frontiersGap_final$Arabic_use, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[36] <- "Domscale"
colnames(frontiersGap_final)[28] <- "English_use_scale"
colnames(frontiersGap_final)[29] <- "Arabic_use_scale"
frontiersGap_final$English_attidutes <- scale(frontiersGap_final$English_attidutes, center = TRUE, scale = TRUE)
frontiersGap_final$Arabic_attidutes <- scale(frontiersGap_final$Arabic_attidutes, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[32] <- "English_att_scale"
colnames(frontiersGap_final)[33] <- "Arabic_att_scale"
frontiersGap_final$English_global <- scale(frontiersGap_final$English_global, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[34] <- "English_glob_scale"
frontiersGap_final$Arabic_global <- scale(frontiersGap_final$Arabic_global, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[35] <- "Arabic_glob_scale"
frontiersGap_final$englishwork <- scale(frontiersGap_final$englishwork, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[37] <- "english_workscale"
frontiersGap_final$aor <- scale(frontiersGap_final$aor, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[5] <- "aor_scale"
frontiersGap_final$lor_sa <- scale(frontiersGap_final$lor_sa, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[6] <- "lorsa_scale"
frontiersGap_final$lor_us <- scale(frontiersGap_final$lor_us, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[7] <- "lorus_scale"
frontiersGap_final$L2onset <- scale(frontiersGap_final$L2onset, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[4] <- "l2onsetscale"
frontiersGap_final$current_age <- scale(frontiersGap_final$current_age, center = TRUE, scale = TRUE)
frontiersGap_final$ses <- scale(frontiersGap_final$ses, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[39] <- "ses"
frontiersGap_final$edu <- scale(frontiersGap_final$edu, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[38] <- "edu"
frontiersGap_final$EnglishVoc <- scale(frontiersGap_final$EnglishVoc, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[40] <- "EnglishVocs"
frontiersGap_final$ArabicVoc <- scale(frontiersGap_final$ArabicVoc, center = TRUE, scale = TRUE)
colnames(frontiersGap_final)[41] <- "ArabicVocs"
```


```{r}
frontiersGap_final %>%
group_by(group) %>%
  summarise(across(where(is.numeric),
    list(mean = ~ mean(.x, na.rm = TRUE), count = ~ sum(!is.na(.x)))))
```


```{r}
library(dplyr)

sum_table_acc <- frontiersGap_final %>%
  mutate(accuracy = as.numeric(as.character(accuracy))) %>%
  group_by(group) %>%
  summarise(
    Total = mean(accuracy)
  ) %>%
  ungroup()

print(sum_table_acc)
```

# Correct answers per group & condition

```{r}
library(data.table)
freqs <- frontiersGap_final |>
  group_by(group, condition) |>
  summarize(total_correct = sum(accuracy),
            fract_correct = total_correct / n()) |>
  arrange(condition, group)

freqs |> data.table()


```


```{r}
remove.packages("Matrix")
install.packages("Matrix", dependencies=TRUE)
```

```{r}
# mod0 <- glmer(as.factor(key_resp_5.CORR) ~ group + (1|group/participant) + (1|condition), family = binomial, data = GapTaskLong, control = glmerControl(check.conv.grad = .makeCC("warning", tol = 5e-2)))

lbfgs_ctrl <- glmerControl()

xls_nb <- frontiersGap_final |>
  mutate(condition = as.factor(condition) |> relevel(ref = "CONG"),
         group = as.factor(group) |> relevel(ref = "AHS"),
         correct = accuracy == 1)

mod_0_frontgap <- glmer(accuracy ~ 1 + (1|participant),
               family = binomial(link = "logit"), 
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_1_frontgap <- glmer(accuracy ~ 1 + (1|participant) + (1|item),
               family = binomial(link = "logit"), 
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_2_frontgap <- glmer(accuracy ~ group + (1|participant),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_3_frontgap <- glmer(accuracy ~ group + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)


print(anova(mod_0_frontgap, mod_1_frontgap, mod_2_frontgap, mod_3_frontgap ))
```

```{r}
print(summary(mod_3_frontgap))
```
```{r}
library(emmeans)
emmeans(mod_3_frontgap, list(pairwise ~ group), adjust = "tukey")
```

```{r}
install.packages("broom.mixed")
```

```{r}
model_params_LDT <- broom.mixed::tidy(mod_3_frontgap)

model_params_LDT|>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = term, y = estimate)) +
  # geom_hline(yintercept = 1, linetype = "dotted", color = "black") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.1, color = "black") +
  geom_point(aes(color = term), size = 3) +
  theme(legend.position = "bottom") +
  labs(y = "Logit", x = "Group")
```
# Here I attempt to perform post-hoc by using emmeans for mod_3 (accuracy)

```{r}
library(emmeans)
emmeans(mod_4_LDT, list(pairwise ~ group), adjust = "tukey")
```


```{r}
mod0_rt_frontgap <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant), data = frontiersGap_final)

mod1_rt_frontgap <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant) + (1|item), data = frontiersGap_final)

mod2_rt_frontgap <- lmer(log_rt_gapfrontiers ~ group + (1|participant), data = frontiersGap_final)

mod3_rt_frontgap <- lmer(log_rt_gapfrontiers ~ group + (1|participant) + (1|item), data = frontiersGap_final)

mod4_rt_frontgap <- lmer(log_rt_gapfrontiers ~ group + length + (1|participant) + (1|item), data = frontiersGap_final)

mod_5_rt_frontgap <- lmer(log_rt_gapfrontiers ~ length + group * condition + (1|participant) + (1|item), data = frontiersGap_final)

mod_6_rt_frontgap <- lmer(log_rt_gapfrontiers ~ length + group * condition + (1|participant) + (1|item) + (1+condition|participant), data = frontiersGap_final)



print(anova(mod0_rt_frontgap, mod1_rt_frontgap, mod2_rt_frontgap, mod3_rt_frontgap, mod4_rt_frontgap, mod_5_rt_frontgap, mod_6_rt_frontgap))
```

```{r}
summary(mod_5_rt_frontgap)
```

```{r}
library(emmeans)
emmeans(mod_5_rt_frontgap, list(pairwise ~ group), adjust = "tukey")
```


```{r}
model_params_rt <- broom.mixed::tidy(mod_5_rt_frontgap)

model_params_rt |> 
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = term, y = estimate)) +
  # geom_hline(yintercept = 1, linetype = "dotted", color = "black") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.1, color = "black") +
  geom_point(aes(color = term), size = 3) +
  theme(legend.position = "bottom") +
  labs(y = "RT", x = "Group")
```
```{r}
mod0_rt <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant), data = frontiersGap_final)

mod1_rt <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant) + (1|item), data = frontiersGap_final)

mod2_rt <- lmer(log_rt_gapfrontiers ~ group + (1|participant), data = frontiersGap_final)

mod3_rt <- lmer(log_rt_gapfrontiers ~ group + length + (1|participant) + (1|item), data = frontiersGap_final)

mod4_rt <- lmer(log_rt_gapfrontiers ~ group + length + group*length + (1|participant) + (1|item) , data = frontiersGap_final)



print(anova(mod0_rt, mod1_rt, mod2_rt, mod3_rt, mod4_rt))
```

```{r}
group_RT1gaplong <- frontiersGap_final %>% filter(group == "RT1")
group_RT2gaplong <- frontiersGap_final %>% filter(group == "RT2")
group_AHSgaplong <- frontiersGap_final %>% filter(group == "AHS")

```

```{r}
# Assuming you have a variable called color_variable in your data frame
scatterplotAHSrtlong <- ggplot(group_AHSgaplong, aes(x = gap_acc_incong, y = English_global, color = English_global)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "maroon") +
  scale_color_viridis() +  # Using the viridis color palette
  labs(
    x = "LDT RT INCONGRUENT TRIALS",
    y = "English_total",
    title = "Scatterplot for AHS"
  ) 

print(scatterplotAHSrtlong)
```

##INCONGRUENT LDT ACCURACY with all BLP variables for RT1
```{r}
cor.test(group_AHSgaplong$English_global, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$English_use, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$English_attidutes, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$Arabic_global, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$Arabic_use, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$Arabic_attidutes, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$Dominance_score, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$aor, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$L2onset, group_AHSgaplong$mean_rt_incong, method = "spearman")
cor.test(group_AHSgaplong$lor_sa, group_AHSgaplong$mean_rt_cong, method = "spearman")
cor.test(group_AHSgaplong$lor_us, group_AHSgaplong$mean_rt_cong, method = "spearman")



```
##INCONGRUENT LDT ACCURACY with all BLP variables for RT2
```{r}
cor.test(group_RT2long$English_global, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$English_use, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$Arabic_global, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$Arabic_use, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$Arabic_attidutes, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$Dominance_score, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$aor, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$L2onset, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$lor_sa, group_RT2long$ldtacc_incong, method = "spearman")
cor.test(group_RT2long$lor_us, group_RT2long$ldtacc_incong, method = "spearman")



```
##INCONGRUENT LDT ACCURACY with all BLP variables for AHS
```{r}
cor.test(group_AHSlong$English_global, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$English_use, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$English_attidutes, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$Arabic_global, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$Arabic_use, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$Arabic_attidutes, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$Dominance_score, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$aor, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$L2onset, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$lor_sa, group_AHSlong$ldtacc_incong, method = "spearman")
cor.test(group_AHSlong$lor_us, group_AHSlong$ldtacc_incong, method = "spearman")



```

```{r}
cor.test(group_AHSlong$English_global, group_AHSlong$accuracy_total, method= "pearson")
cor.test(group_RT1long$English_global, group_RT1long$accuracy_total, method= "pearson")
cor.test(group_RT2long$English_global, group_RT2long$accuracy_total, method= "pearson")

#the age of return among returnees
cor.test(group_RT1long$ldtacc_cong, group_RT1long$accuracy_total, method= "spearman")
cor.test(group_RT2long$aor, group_RT2long$accuracy_total, method= "pearson")

#English use
cor.test(group_RT1long$ldtacc_incong, group_RT1long$English_global, method= "pearson")
cor.test(group_RT2long$ldtacc_incong, group_RT2long$English_global, method= "pearson")
cor.test(group_AHSlong$ldtacc_incong, group_AHSlong$English_global, method= "pearson")
cor.test(group_RT1long$rt_mean_total, group_RT1long$Arabic_global, method= "pearson")
cor.test(group_RT2long$rt_mean_total, group_RT2long$Arabic_global, method= "pearson")
  cor.test(group_AHSlong$rt_mean_total, group_AHSlong$Arabic_use, method= "pearson")

# conditions
cor.test(group_RT1long$English_use, group_RT1long$accuracy, method= "pearson")

cor.test(group_RT2long$English_global, group_RT2long$accuracy_total, method= "pearson")

unique(group_RT1long$aor)

```
## Attitudes with LDT ACCURACY AND RT

```{r}
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtacc_incong, method= "pearson")
cor.test(group_RT1long$English_attidutes, group_RT1long$ldtacc_incong, method= "pearson")
cor.test(group_AHSlong$English_attidutes, group_AHSlong$ldtacc_incong, method= "pearson")
```


## coding level factors
```{r}
frontiersGap_final$Condition = ifelse(frontiersGap_final$condition == "CONG", -0.5, 0.5)
```


CONGRUENT ACCURACY WTH BLP AHS
```{r}
cor.test(group_AHSlong$English_global, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$English_use, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$English_attidutes, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$Arabic_global, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$Arabic_use, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$Arabic_attidutes, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$Dominance_score, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$aor, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$L2onset, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$lor_sa, group_AHSlong$ldtacc_cong, method = "spearman")
cor.test(group_AHSlong$lor_us, group_AHSlong$ldtacc_cong, method = "spearman")



```

CONGRUENT ACCURACY WTH BLP RT1
```{r}
cor.test(group_RT1long$English_global, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$English_use, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$English_attidutes, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$Arabic_global, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$Arabic_use, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$Arabic_attidutes, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$Dominance_score, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$aor, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$L2onset, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$lor_sa, group_RT1long$ldtacc_cong, method = "spearman")
cor.test(group_RT1long$lor_us, group_RT1long$ldtacc_cong, method = "spearman")



```

CONGRUENT ACCURACY WTH BLP RT2
```{r}
cor.test(group_RT2long$English_global, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$English_use, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$Arabic_global, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$Arabic_use, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$Arabic_attidutes, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$Dominance_score, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$aor, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$L2onset, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$lor_sa, group_RT2long$ldtacc_cong, method = "spearman")
cor.test(group_RT2long$lor_us, group_RT2long$ldtacc_cong, method = "spearman")



```


RT INCONGRUENT RT2

```{r}
cor.test(group_RT2long$English_global, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$English_use, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_global, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_use, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_attidutes, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Dominance_score, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$aor, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$L2onset, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$lor_sa, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$lor_us, group_RT2long$ldtrt_incong, method = "spearman")



```
RT INCONGRUENT RT1

```{r}
cor.test(group_RT2long$English_global, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$English_use, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_global, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_use, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Arabic_attidutes, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$Dominance_score, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$aor, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$L2onset, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$lor_sa, group_RT2long$ldtrt_incong, method = "spearman")
cor.test(group_RT2long$lor_us, group_RT2long$ldtrt_incong, method = "spearman")



```

RT INCONGRUENT AHS

```{r}
cor.test(group_RT1long$English_global, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$English_use, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$English_attidutes, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$Arabic_global, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$Arabic_use, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$Arabic_attidutes, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$Dominance_score, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$aor, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$L2onset, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$lor_sa, group_RT1long$ldtrt_incong, method = "spearman")
cor.test(group_RT1long$lor_us, group_RT1long$ldtrt_incong, method = "spearman")



```
RT CONGRUENT AHS

```{r}
cor.test(group_RT1long$English_global, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$English_use, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$English_attidutes, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$Arabic_global, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$Arabic_use, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$Arabic_attidutes, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$Dominance_score, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$aor, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$L2onset, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$lor_sa, group_RT1long$acc_nonwithout, method = "spearman")
cor.test(group_RT1long$lor_us, group_RT1long$acc_nonwithout, method = "spearman")



```
aor
```{r}
cor.test(group_RT1long$aor, group_RT1long$rt_mean_total, method = "spearman")
cor.test(group_RT2long$aor, group_RT2long$rt_mean_total, method = "spearman")
```
```{r}
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtacc_cong, method = "pearson")
cor.test(group_RT2long$English_attidutes, group_RT2long$ldtacc_incong, method = "pearson")
```

```{r}
set.seed(123)
group_RT2gaplong <- data.frame(
  condition = rep(c("CONG", "INCONG"), each = 50),
  key_resp_5_corr = sample(0:1, 100, replace = TRUE)
)
```
```{r}
library(dplyr)
library(broom)
```

```{r}
# Convert condition to a factor if it's not already
group_RT2gaplong$condition <- as.factor(group_RT2gaplong$condition)
group_RT2gaplong$key_resp_5_corr <- as.numeric(as.character(group_RT2gaplong$key_resp_5_corr))
```


```{r}
cor_by_condition <- group_RT2gaplong %>%
  group_by(condition) %>%
  summarize(spearman_cor = cor.test(group_RT2gaplong$key_resp_5_corr, group_RT2gaplong$condition, method = "spearman")$estimate)
# Display the results
print(cor_by_condition)
```
```{r}
# Assuming your data.frame is named group_RT2gaplong
# Example data
set.seed(123)
group_RT2gaplong <- data.frame(
  condition = rep(c("CONG", "INCONG"), each = 50),
  key_resp_5_corr = as.character(sample(0:1, 100, replace = TRUE))
)

# Load necessary libraries
library(dplyr)
library(broom)

# Convert key_resp_5_corr to numeric if it's not already
group_RT2gaplong$key_resp_5_corr <- as.numeric(as.character(group_RT2gaplong$key_resp_5_corr))
group_RT2gaplong$condition <- as.factor(group_RT2gaplong$condition)

# Check for NAs after conversion
if (any(is.na(group_RT2gaplong$key_resp_5_corr))) {
  stop("Some values in key_resp_5_corr could not be converted to numeric.")
}

# Calculate Spearman correlation for each condition
cor_by_condition <- group_RT2gaplong %>%
  group_by(condition) %>%
  summarize(spearman_cor = cor.test(key_resp_5_corr, condition, method = "spearman")$estimate)

# Display the results
print(cor_by_condition)
```
```{r}
# Assuming your data.frame is named group_RT2gaplong
# Example data
set.seed(123)
group_RT2gaplong <- data.frame(
  condition = rep(c("CONG", "INCONG"), each = 50),
  key_resp_5_corr = as.character(sample(0:1, 100, replace = TRUE))
)

# Load necessary libraries
library(dplyr)

# Convert key_resp_5_corr to numeric if it's not already
group_RT2gaplong$key_resp_5_corr <- as.numeric(as.character(group_RT2gaplong$key_resp_5_corr))

# Check for NAs after conversion
if (any(is.na(group_RT2gaplong$key_resp_5_corr))) {
  stop("Some values in key_resp_5_corr could not be converted to numeric.")
}

# Calculate Spearman correlation for each condition
cor_by_condition <- group_RT2gaplong %>%
  group_by(condition) %>%
  summarize(spearman_cor = cor.test(group_RT2gaplong$key_resp_5_corr, group_RT2gaplong$condition, method = "spearman")$estimate)

# Display the results
print(cor_by_condition)
```
```{r}
# Calculate point-biserial correlation
cor_result <- cor(group_RT2gaplong$key_resp_5_corr, group_RT2gaplong$Arabic_global)

# Print the result
print(paste("Point-biserial correlation coefficient: ", cor_result))
cor_test_result <- cor.test(group_RT2gaplong$key_resp_5_corr, group_RT2gaplong$English_global)
print(cor_test_result)
```

```{r}
# Define 'condition' in the global environment
condition <- TRUE

# Define the function without requiring 'condition' as an argument
myFunction <- function() {
  # Capture the match call
  mc <- match.call()
  # Print the match call for debugging purposes
  print(mc) # For debugging: print the captured call
  # Print the variables in the parent frame for debugging purposes
  print(ls(envir = parent.frame(1L))) # For debugging: list variables in the parent frame
  # Evaluate the match call in the parent frame
  eval(mc, parent.frame(1L))
}

# Call the function; 'condition' is found in the global environment
myFunction()
```

models with dominance score only:

```{r}
# mod0 <- glmer(as.factor(key_resp_5.CORR) ~ group + (1|group/participant) + (1|condition), family = binomial, data = GapTaskLong, control = glmerControl(check.conv.grad = .makeCC("warning", tol = 5e-2)))

lbfgs_ctrl <- glmerControl()

xls_nb <- frontiersGap_final |>
  mutate(condition = as.factor(condition) |> relevel(ref = "CONG"),
         group = as.factor(group) |> relevel(ref = "AHS"),
         correct = accuracy == 1)

mod_0_frontgap <- glmer(accuracy ~ 1 + (1|participant),
               family = binomial(link = "logit"), 
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_1_frontgap <- glmer(accuracy ~ 1 + (1|participant) + (1|item),
               family = binomial(link = "logit"), 
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_2_frontgap <- glmer(accuracy ~ 1 + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_3_frontgap <- glmer(accuracy ~ 1 + (1|participant) + (1|item) + (1+condition | participant),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_4_frontgap <- glmer(accuracy ~ Domscale * condition + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_5_frontgap <- glmer(accuracy ~ Domscale * condition + (1|participant) + (1|item) +  (1+condition | participant),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)

mod_6_frontgap <- glmer(accuracy ~ Domscale * condition + (1|participant) + (1|item) +  (1+condition | participant) + (1 + item | participant),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
               control = lbfgs_ctrl)



print(anova(mod_0_frontgap, mod_1_frontgap, mod_2_frontgap, mod_3_frontgap, mod_4_frontgap, mod_5_frontgap, mod_6_frontgap ))
```
```{r}
summary(mod_4_frontgap)
```

# missing values
```{r}
frontiers_gap_clean <- na.omit(frontiersGap_final)
```

```{r}
library(car)
vif(model)
```


models with individual scales
```{r}


mod_1_LDTii <- glmer(accuracy ~  condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu  + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
                control = glmerControl(optimizer = "bobyqa")
)

mod_2_LDTii <- glmer(accuracy ~  condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu + EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
                control = glmerControl(optimizer = "bobyqa")
)

mod_3_LDTii <- glmer(accuracy ~ condition + english_workscale + English_use_scale*condition + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale  + ses + edu +(1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
              control = glmerControl(optimizer = "bobyqa")
)

mod_4_LDTii <- glmer(accuracy ~  condition + english_workscale + English_use_scale*condition + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu + EnglishVocs + ArabicVocs +(1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
                 control = glmerControl(optimizer = "bobyqa")
)

mod_5_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu +EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
              control = glmerControl(optimizer = "bobyqa")
)

mod_6_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale + aor_scale +l2onsetscale + lorus_scale + ses + edu + lorsa_scale +EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
                 control = glmerControl(optimizer = "bobyqa")
)

mod_7_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition + aor_scale +l2onsetscale + lorus_scale + lorsa_scale+ ses + edu  +EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
                control = glmerControl(optimizer = "bobyqa")
)

mod_8_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition + aor_scale*condition +l2onsetscale + lorus_scale + lorsa_scale + ses + edu +EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
                 control = glmerControl(optimizer = "bobyqa")
)
mod_9_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition + aor_scale*condition +l2onsetscale*condition + lorus_scale + lorsa_scale+ ses + edu  +EnglishVocs + ArabicVocs + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
             control = glmerControl(optimizer = "bobyqa")
)
mod_10_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition + aor_scale*condition +l2onsetscale*condition + lorus_scale*condition + lorsa_scale+ ses + edu  + EnglishVocs + ArabicVocs +(1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,

              control = glmerControl(optimizer = "bobyqa")
)
mod_11_LDTii <- glmer(accuracy ~ condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition + aor_scale*condition +l2onsetscale*condition + lorus_scale*condition + lorsa_scale*condition + ses + edu + EnglishVocs + ArabicVocs +(1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,

                 control = glmerControl(optimizer = "bobyqa")
)

print(anova(mod_1_LDTii, mod_2_LDTii,mod_3_LDTii, mod_4_LDTii, mod_5_LDTii, mod_6_LDTii, mod_7_LDTii, mod_8_LDTii, mod_9_LDTii,mod_10_LDTii, mod_11_LDTii ))

```
```{r}
# Assuming you have a binomial logistic regression model
library(lme4)
library(MuMIn)

mod_glmer <- glmer(accuracy ~ condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale + l2onsetscale + lorus_scale + lorsa_scale + ses + edu + (1 | participant) + (1 | item),
                   family = binomial(link = "logit"),
                   data = frontiersGap_final)
# Compute R² values
r2_glmer <- r.squaredGLMM(mod_glmer)

# Display marginal and conditional R²
print(r2_glmer)
```


```{r}
summary(mod_1_LDTii)
```

```{r}


mod_2_LDTii <- glmer(accuracy ~ current_age + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
                control = glmerControl(optimizer = "bobyqa")
)

mod_12_LDTii <- glmer(accuracy ~ current_age + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale  + ses + edu  + (1|participant) + (1|item),
               family = binomial(link = "logit"),
               data = frontiersGap_final,
              control = glmerControl(optimizer = "bobyqa")
)

mod_3_LDTii <- glmer(accuracy ~ current_age + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu + (1|participant) + (1|item) + (1+condition | participant),
               family = binomial(link = "logit"),
               data = frontiersGap_final ,
                 control = glmerControl(optimizer = "bobyqa")
)

              
              
print(anova( mod_2_LDTii,mod_12_LDTii,mod_3_LDTii ))


```

```{r}
summary(mod_12_LDTii)
```

```{r}
# Install and load the car package
install.packages("car")
library(car)

# Calculate VIFs
vif(mod_3_iglobalgaprt)
```
rt with dominance score on the gap task

```{r}
mod0_rtdom <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant), data = frontiersGap_final)

mod1_rtdom <- lmer(log_rt_gapfrontiers ~ 1 + (1|participant) + (1|item), data = frontiersGap_final)

mod2_rtdom <- lmer(log_rt_gapfrontiers ~ Domscale*condition + length + (1|participant), data = frontiersGap_final)

mod3_rtdom <- lmer(log_rt_gapfrontiers ~ Domscale*condition + length + (1|participant) + (1|item), data = frontiersGap_final)

mod4_rtdom <- lmer(log_rt_gapfrontiers ~ Domscale*condition + length + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + (1|participant) + (1|item), data = frontiersGap_final)

mod5_rtdom <- lmer(log_rt_gapfrontiers ~ Domscale*condition + length + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + (1|participant) + (1|item) + (1+condition | participant) + (1+item | participant), data = frontiersGap_final)


print(anova(mod0_rtdom, mod1_rtdom, mod2_rtdom, mod3_rtdom, mod4_rtdom,mod5_rtdom ))
```
```{r}
summary(mod3_rtdom)
```

models with individual scales
```{r}

mod_3_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu +  (1|participant) + (1|item) , data = frontiersGap_final)

mod_4_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu +EnglishVocs +ArabicVocs+  (1|participant) + (1|item) , data = frontiersGap_final)

mod_5_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale + English_use_scale*condition + Arabic_use_scale + Arabic_att_scale + English_att_scale  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu + (1|participant) + (1|item), data = frontiersGap_final)

mod_6_iglobalgaprt <- lmer(log_rt_gapfrontiers ~length + condition + english_workscale + English_use_scale*condition + Arabic_use_scale + Arabic_att_scale + English_att_scale  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + EnglishVocs +ArabicVocs+ (1|participant) + (1|item) + ses + edu , data = frontiersGap_final)


mod_7_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale  + aor_scale +l2onsetscale + lorus_scale+ ses + edu  + lorsa_scale + EnglishVocs +ArabicVocs+ (1|participant) + (1|item) , data = frontiersGap_final)

mod_8_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale+ ses + edu  + EnglishVocs +ArabicVocs+ (1|participant) + (1|item), data = frontiersGap_final)

mod_9_iglobalgaprt <- lmer(log_rt_gapfrontiers ~length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition  + aor_scale*condition +l2onsetscale + lorus_scale + lorsa_scale+ ses + edu  +  EnglishVocs +ArabicVocs+(1|participant) + (1|item) , data = frontiersGap_final)

mod_10_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition  + aor_scale*condition +l2onsetscale*condition + lorus_scale + lorsa_scale+ ses + edu  +EnglishVocs +ArabicVocs+  (1|participant) + (1|item) , data = frontiersGap_final)

mod_11_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition  + aor_scale*condition +l2onsetscale*condition + lorus_scale*condition + lorsa_scale+ ses + edu  + EnglishVocs +ArabicVocs+ (1|participant) + (1|item) , data = frontiersGap_final)

mod_12_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale*condition + English_use_scale*condition + Arabic_use_scale*condition + Arabic_att_scale*condition + English_att_scale*condition  + aor_scale*condition +l2onsetscale*condition + lorus_scale*condition + lorsa_scale*condition+ ses + edu  + EnglishVocs +ArabicVocs+ (1|participant) + (1|item) , data = frontiersGap_final)

print(anova(mod_3_iglobalgaprt, mod_4_iglobalgaprt, mod_5_iglobalgaprt, mod_6_iglobalgaprt, mod_7_iglobalgaprt, mod_8_iglobalgaprt, mod_9_iglobalgaprt, mod_10_iglobalgaprt, mod_11_iglobalgaprt, mod_12_iglobalgaprt))
```
```{r}
summary(mod_3_iglobalgaprt)
```

```{r}
# Assuming you have a linear mixed model
library(lme4)
install.packages("MuMIn")
library(MuMIn)

# Fit the model
mod_lmer <- lmer(log_rt_gapfrontiers ~ length + condition + english_workscale + English_use_scale + Arabic_use_scale + Arabic_att_scale + English_att_scale  + aor_scale +l2onsetscale + lorus_scale + lorsa_scale + ses + edu +  (1|participant) + (1|item) , data = frontiersGap_final)


# Compute R² values
r2_lmer <- r.squaredGLMM(mod_lmer)

# Display marginal and conditional R²
print(r2_lmer)
```

```{r}
library(ggeffects)
library(ggplot2)

effect_plot <- ggpredict(mod_3_iglobalgaprt, terms = "English_att_scale [all]")

# If you want the reaction time, exponentiate the predicted log values
effect_plot$predicted <- exp(effect_plot$predicted)
effect_plot$conf.low <- exp(effect_plot$conf.low)
effect_plot$conf.high <- exp(effect_plot$conf.high)

ggplot(effect_plot, aes(x = x, y = predicted)) +
  geom_line() +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  labs(x = "English Work Scale", y = "Predicted Reaction Time") +
  theme_minimal()
```


```{r}
library(broom.mixed)
library(ggplot2)

# Extract the fixed effects
fixed_effects <- tidy(mod_3_iglobalgaprt, effects = "fixed")

# Create prediction grid
newdata <- expand.grid(
  aor_scale = seq(min(data$aor_scale), max(data$aor_scale), length = 100),
  English_att_scale = seq(min(data$English_att_scale), max(data$English_att_scale), length = 100),
  currentage = mean(data$currentage),
  length = mean(data$length),
  ...
)

# Add predictions
newdata$predicted <- predict(mod_3_iglobalgaprt, newdata, re.form = NA)

# Plot
ggplot(newdata, aes(x = aor_scale, y = predicted, color = English_att_scale)) +
  geom_line() +
  labs(x = "Age of Return", y = "Predicted Log Reaction Time", color = "English Attitudes")
```

collinearity check 
```{r}
install.packages("car")

# Load the package
library(car)

# Fit the model without random effects
fixed_effects_model <- lm(log_rt_gapfrontiers ~ condition * English_use_scale + 
                          english_workscale + Arabic_use_scale + Arabic_att_scale + 
                          English_att_scale + aor_scale + l2onsetscale + 
                          lorus_scale + lorsa_scale, data = frontiersGap_final)

# Calculate VIF
vif_values <- vif(fixed_effects_model)
print(vif_values)
```

```{r}
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = term, y = estimate, color = term)) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.3, color = "black") +
  geom_point(size = 2) +
  scale_color_manual(values = c("red", "blue", "green", "orange", "purple", "pink", "yellow", "maroon", "black", "brown", "beige", "grey", "magenta", "cyan","seagreen" "skyblue", "darkgray", "navyblue", "lightgrey","darkmagenta" )) +  # Adjust the colors as needed
  theme(legend.position = "bottom") +
  labs(y = "RT", x = "Group")
```
```{r}
# Load necessary libraries
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Tidy up model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Plotting the estimates of fixed effects
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = term, y = estimate, color = term)) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), 
                width = 0.3, color = "black") +
  geom_point(size = 2) +
  scale_color_manual(values = c("red", "blue", "green", "orange", "purple", 
                                 "pink", "yellow", "maroon", "black", "brown", 
                                 "beige", "grey", "magenta", "cyan", "seagreen", 
                                 "skyblue", "darkgray", "navyblue", "lightgrey", 
                                 "darkmagenta")) +  # Adjust the colors as needed
  theme(legend.position = "bottom") +
  labs(y = "Reaction Time (RT)", x = "Group")
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Create a dot-and-whisker plot
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = estimate, y = term)) +
  geom_point(size = 3, color = "blue") + 
  geom_errorbarh(aes(xmin = estimate - std.error, xmax = estimate + std.error), height = 0.2) +
  theme_minimal() +
  labs(x = "Estimated Effect", y = "Predictors") +
  ggtitle("Dot-and-Whisker Plot of Model Parameters")
```
```{r}
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_brewer(palette = "Set3")
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Create a bar plot
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = c("currentage" = "red", "length" = "blue", 
                                "english_workscale" = "green", "English_use_scale" = "orange", 
                                "Arabic_use_scale" = "purple", "Arabic_att_scale" = "pink", 
                                "English_att_scale" = "yellow", "aor_scale" = "maroon", 
                                "l2onsetscale" = "black", "lorus_scale" = "brown", 
                                "lorsa_scale" = "beige", "ses" = "grey", 
                                "edu" = "cyan")) +  # Specify colors for each term
  theme(legend.position = "none")  # Optional: remove the legend if you don't want it
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Create a bar plot with colors for each term
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_brewer(palette = "Set3") +  # Using a color palette for filling
  theme(legend.position = "right")  # Ensure the legend is positioned to the right
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Filter and ensure terms are factors
model_params <- model_params |>
  filter(!str_detect(term, "sd")) |>
  mutate(term = factor(term, levels = unique(term)))  # Set factor levels

# Specify the colors for each term
color_palette <- c(
  "currentage" = "red",
  "length" = "blue",
  "english_workscale" = "green",
  "English_use_scale" = "orange",
  "Arabic_use_scale" = "purple",
  "Arabic_att_scale" = "pink",
  "English_att_scale" = "yellow",
  "aor_scale" = "maroon",
  "l2onsetscale" = "black",
  "lorus_scale" = "brown",
  "lorsa_scale" = "beige",
  "ses" = "grey",
  "edu" = "cyan"
)

# Create a bar plot with custom colors and legend
model_params |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = color_palette) +  # Use the custom color palette
  theme(legend.position = "right", 
        legend.title = element_blank())  # Position and remove the title from the legend
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Filter and ensure terms are factors
model_params <- model_params |>
  filter(!str_detect(term, "sd")) |>
  mutate(term = factor(term, levels = unique(term)))  # Set factor levels

# Specify the spring colors for each term
color_palette <- c(
  "currentage" = "#FFB6C1",   # Light Pink
  "length" = "#98FB98",       # Pale Green
  "english_workscale" = "#FFDAB9", # Peach
  "English_use_scale" = "#FFE4E1",  # Misty Rose
  "Arabic_use_scale" = "#E6E6FA",   # Lavender
  "Arabic_att_scale" = "#FFFACD",   # Lemon Chiffon
  "English_att_scale" = "#F0E68C",   # Khaki
  "aor_scale" = "#B0E0E6",         # Powder Blue
  "l2onsetscale" = "#F5FFFA",       # Mint Cream
  "lorus_scale" = "#FAF0E6",        # Linen
  "lorsa_scale" = "#FFEFD5",        # Papaya Whip
  "ses" = "#F5F5DC",                # Beige
  "edu" = "#FFDEAD"                 # Navajo White
)

# Create a bar plot with custom colors and legend
model_params |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = color_palette) +  # Use the custom color palette
  theme(legend.position = "right", 
        legend.title = element_blank())  # Position and remove the title from the legend
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Filter and ensure terms are factors
model_params <- model_params |>
  filter(!str_detect(term, "sd")) |>
  mutate(term = factor(term, levels = unique(term)))  # Set factor levels

# Specify softer spring colors for each term
color_palette <- c(
  "currentage" = "#D4E157",   # Soft Lime Green
  "length" = "#A5D6D1",       # Soft Teal
  "english_workscale" = "#FFABAB", # Soft Salmon
  "English_use_scale" = "#FFEBA1",  # Light Gold
  "Arabic_use_scale" = "#E1BEE7",   # Soft Lavender
  "Arabic_att_scale" = "#C5E1A5",   # Soft Light Green
  "English_att_scale" = "#FFCCBC",   # Soft Peach
  "aor_scale" = "#B2DFDB",         # Soft Turquoise
  "l2onsetscale" = "#B3E5FC",       # Soft Sky Blue
  "lorus_scale" = "#FFECB3",        # Soft Cream
  "lorsa_scale" = "#FFE0B2",        # Light Apricot
  "ses" = "#EDE7F6",                # Soft Light Lavender
  "edu" = "#FFF3E0"                 # Soft Light Orange
)

# Create a bar plot with custom colors and legend
model_params |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = color_palette) +  # Use the custom color palette
  theme(legend.position = "right", 
        legend.title = element_blank())  # Position and remove the title from the legend
```
```{r}
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(stringr)

# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Filter and ensure terms are factors
model_params <- model_params |>
  filter(!str_detect(term, "sd")) |>
  mutate(term = factor(term, levels = unique(term)))  # Set factor levels

# Specify darker spring colors for each term
color_palette <- c(
  "currentage" = "#C5E1A5",   # Darker Lime Green
  "length" = "#00796B",       # Darker Teal
  "english_workscale" = "#E53935", # Darker Salmon
  "English_use_scale" = "#FFD54F",  # Darker Gold
  "Arabic_use_scale" = "#8E24AA",   # Darker Lavender
  "Arabic_att_scale" = "#4CAF50",   # Darker Light Green
  "English_att_scale" = "#FF6F20",   # Darker Peach
  "aor_scale" = "#FFABAB",         # Darker Turquoise
  "l2onsetscale" = "#0288D1",       # Darker Sky Blue
  "lorus_scale" = "#FBC02D",        # Darker Cream
  "lorsa_scale" = "#FF8A65",        # Darker Apricot
  "ses" = "#E1BEE7",                # Darker Lavender
  "edu" = "#A5D6D1"                 # Darker Light Orange
)

# Rename predictors in a named vector
new_names <- c(
  "currentage" = "Current Age",
  "length" = "Length of Residence",
  "english_workscale" = "English Work ",
  "English_use_scale" = "English Use",
  "Arabic_use_scale" = "Arabic Use",
  "Arabic_att_scale" = "Arabic Attitudes",
  "English_att_scale" = "English Attitudes",
  "aor_scale" = "Age of Return",
  "l2onsetscale" = "L2 Onset Age",
  "lorus_scale" = "Length of Stay (US)",
  "lorsa_scale" = "Length of Stay (SA)",
  "ses" = "Socioeconomic Status",
  "edu" = "Educational Level"
)

# Update the term labels in the model_params data frame
model_params$term <- recode(model_params$term, !!!new_names)

# Create a bar plot with custom colors and legend
model_params |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = color_palette) +  # Use the custom color palette
  theme(legend.position = "right", 
        legend.title = element_blank())  # Position and remove the title from the legend
```
```{r}
# Get the model parameters and filter out standard deviation terms
model_params <- broom.mixed::tidy(mod_1_LDTii)

# Filter and ensure terms are factors
model_params <- model_params |>
  filter(!str_detect(term, "sd")) |>
  mutate(term = factor(term, levels = unique(term)))  # Set factor levels

# Specify darker spring colors for each term (with new names)
color_palette <- c(
  "Current Age" = "#E1BEE7",   # Darker Lime Green
  "Length of Residence" = "#B3E5FC",       # Darker Teal
  "English Work Scale" = "#E53935", # Darker Salmon
  "English Use" = "#FFD54F",  # Darker Gold
  "Arabic Use" = "#8E24AA",   # Darker Lavender
  "Arabic Attitudes" = "#4CAF50",   # Darker Light Green
  "English Attitudes" = "#FFB6C1",   # Darker Peach
  "Age of Return" = "#FFDEAD",         # Darker Turquoise
  "L2 Onset Age" = "#0288D1",       # Darker Sky Blue
  "Length of Stay (US)" = "#E1BEE7",        # Darker Cream
  "Length of Stay (SA)" = "#FF8A65",        # Darker Apricot
  "Socioeconomic Status" = "#C5E1A5",                # Darker Lavender
  "Educational Level" = "#E53935"                 # Darker Light Orange
)

# Rename predictors in a named vector
new_names <- c(
  "currentage" = "Current Age",
  "length" = "Length of Residence",
  "english_workscale" = "English Work",
  "English_use_scale" = "English Use",
  "Arabic_use_scale" = "Arabic Use",
  "Arabic_att_scale" = "Arabic Attitudes",
  "English_att_scale" = "English Attitudes",
  "aor_scale" = "Age of Return",
  "l2onsetscale" = "L2 Onset Age",
  "lorus_scale" = "Length of Stay (US)",
  "lorsa_scale" = "Length of Residence (SA)",
  "ses" = "Socioeconomic Status",
  "edu" = "Educational Level"
)

# Update the term labels in the model_params data frame
model_params$term <- recode(model_params$term, !!!new_names)

# Create a bar plot with custom colors and legend
model_params |>
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = term)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Bar Plot of Model Parameters") +
  scale_fill_manual(values = color_palette) +  # Use the custom color palette
  theme(legend.position = "right", 
        legend.title = element_blank())  # Position and remove the title from the legend
```

```{r}
# Assuming you have another grouping variable (e.g., group)
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = estimate, y = term)) +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  labs(x = "Estimated Effect", y = "Predictors") +
  ggtitle("Faceted Plot of Model Parameters") +
  facet_wrap(~ term, scales = "free_y")  # Create facets by term
```
```{r}
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = reorder(term, estimate), y = estimate)) +
  geom_segment(aes(xend = term, yend = estimate - std.error), color = "grey") +
  geom_point(size = 4, color = "orange") +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  theme_minimal() +
  coord_flip() +  # Flip coordinates for better readability
  labs(x = "Predictors", y = "Estimated Effect", title = "Lollipop Plot of Model Parameters")
```
```{r}
# Example: Simulate some data for the purpose of a violin plot
set.seed(123)
# Create a sample dataset with random normal data for the predictors
simulated_data <- data.frame(
  term = rep(c("currentage", "length", "english_workscale", "English_use_scale", "Arabic_use_scale", "Arabic_att_scale", "English_att_scale", "aor_scale", "l2onsetscale", "lorus_scale", "lorsa_scale", "ses", "edu"), each = 100),
  estimate = rnorm(1300, mean = 0, sd = 1)  # Simulated estimates for each term
)

# Create a violin plot using the simulated data
ggplot(simulated_data, aes(x = term, y = estimate)) +
  geom_violin(fill = "lightblue") +
  theme_minimal() +
  labs(x = "Predictors", y = "Simulated Estimated Effect", title = "Violin Plot of Simulated Model Estimates")
```

```{r}
library(ggplot2)
library(broom.mixed)
library(dplyr)
library(stringr)

# Extract model estimates
model_params <- broom.mixed::tidy(mod_3_iglobalgaprt)

# Filter out standard deviations and create the plot
model_params |>
  filter(!str_detect(term, "sd")) |>
  ggplot(aes(x = term, y = estimate, color = term)) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.3, color = "black") +
  geom_point(size = 2) +
  scale_color_manual(values = c("red", "blue", "green", "orange", "purple", "pink", "yellow", "maroon", "black", "brown", "beige", "grey", "magenta", "cyan", "seagreen", "skyblue", "darkgray", "navyblue", "lightgrey", "darkmagenta")) +  # Adjust colors as needed
  theme(legend.position = "bottom") +
  labs(y = "Estimate", x = "Term") +  # Adjust labels as needed
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

```{r}
mod_3_iglobalgaprt <- lmer(log_rt_gapfrontiers ~ currentage + length + condition +
  english_workscale * condition + English_use_scale + Arabic_use_scale + Arabic_att_scale +
  English_att_scale + aor_scale + l2onsetscale + lorus_scale + lorsa_scale +
  (1 | participant) + (1 | item) + (1 + condition | participant), data = frontiersGap_final)

# Get fitted values and random effects for participants
frontiersGap_final <- frontiersGap_final %>%
  mutate(predicted_log_rt = predict(mod_3_iglobalgaprt, re.form = NA)) %>%
  group_by(participant) %>%
  mutate(predicted_log_rt = mean(predicted_log_rt))

# Create the plot
ggplot(frontiersGap_final, aes(x = factor(participant), y = predicted_log_rt)) +
  geom_point(aes(color = factor(participant)), alpha = 0.7) +
  labs(title = "Predicted Reaction Time by Participant",
       x = "Participant",
       y = "Predicted Log Reaction Time") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
```{r}
# Add predictions directly to the data
frontiersGap_final$predicted_log_rt <- fitted(mod_3_iglobalgaprt)

# Plot individual predictions
ggplot(frontiersGap_final, aes(x = factor(participant), y = predicted_log_rt)) +
  geom_point(aes(color = factor(participant)), alpha = 0.7) +
  labs(title = "Predicted Reaction Time by Participant",
       x = "Participant",
       y = "Predicted Log Reaction Time") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
```{r}
# Predicted values for English Attitudes
english_att_emm <- emmeans(mod_3_iglobalgaprt, ~ English_att_scale)

# Convert to data frame
english_att_df <- as.data.frame(english_att_emm)

# Plot the effect of English Attitudes
ggplot(english_att_df, aes(x = English_att_scale, y = emmean)) +
  geom_line(color = "green") +
  geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.2, fill = "green") +
  labs(title = "Effect of English Attitudes on Reaction Time",
       x = "English Attitudes (Scaled)",
       y = "Predicted Log Reaction Time") +
  theme_minimal()
```
```{r}
sjPlot::plot_model(mod_3_iglobalgaprt)
```
```{r}
cor_matrix <- cor(frontiersGap_final)
print(cor_matrix)
```
```{r}
numeric_data <- frontiersGap_final %>%
  select_if(is.numeric)

# Compute the correlation matrix
cor_matrix <- cor(numeric_data, use = "complete.obs")
print(cor_matrix)

# Optionally, visualize the correlation matrix

corrplot(cor_matrix, method = "circle")
```
```{r}

library (ggcorrlpot)
# Plot correlation matrix using corrplot
corrplot(cor_matrix, method = "circle")

# Plot correlation matrix using ggcorrplot
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", lab = TRUE)
```

`